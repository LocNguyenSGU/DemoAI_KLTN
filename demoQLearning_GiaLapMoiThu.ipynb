{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab003aa",
   "metadata": {},
   "source": [
    "## Demo Qlearning cho kho√° lu·∫≠n t·ªët nghi·ªáp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39c9055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# -----------------------------\n",
    "# Danh s√°ch c√°c tr·∫°ng th√°i b·∫°n mu·ªën hu·∫•n luy·ªán (c√≥ th·ªÉ m·ªü r·ªông)\n",
    "# -----------------------------\n",
    "initial_state_pool = [\n",
    "    {\n",
    "        \"quiz_avg_scores\": {\"easy\": 7.2, \"medium\": 2, \"hard\": None},\n",
    "        \"pdf_views\": {\"PDF_1_2_1\": 100, \"PDF_1_2_2\": 0},\n",
    "        \"video_views\": {\"VID_1_2_1\": 1, \"VID_1_2_2\": 0, \"VID_1_2_3\": 0},\n",
    "        \"forum_post_count\": 1,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 2\n",
    "    },\n",
    "    {\n",
    "        \"quiz_avg_scores\": {\"easy\": 5.5, \"medium\": None, \"hard\": None},\n",
    "        \"pdf_views\": {\"PDF_1_2_1\": 2, \"PDF_1_2_2\": 1},\n",
    "        \"video_views\": {\"VID_1_2_1\": 0, \"VID_1_2_2\": 2, \"VID_1_2_3\": 1},\n",
    "        \"forum_post_count\": 0,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 1\n",
    "    },\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Danh s√°ch h√†nh ƒë·ªông c√≥ th·ªÉ th·ª±c hi·ªán\n",
    "# -----------------------------\n",
    "ACTIONS = [\n",
    "    \"xem_pdf:PDF_1_2_1\",\n",
    "    \"xem_pdf:PDF_1_2_2\",\n",
    "    \"xem_video:VID_1_2_1\",\n",
    "    \"xem_video:VID_1_2_2\",\n",
    "    \"xem_video:VID_1_2_3\",\n",
    "    \"lam_quiz:QUIZ_1_2_EASY\",\n",
    "    \"lam_quiz:QUIZ_1_2_MEDIUM\",\n",
    "    \"lam_quiz:QUIZ_1_2_HARD\",\n",
    "    \"tham_gia_thao_luan\",\n",
    "    \"nop_assignment\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Mock m√¥ h√¨nh d·ª± ƒëo√°n ƒëi·ªÉm (Linear Regression)\n",
    "# -----------------------------\n",
    "def predict_easy_score(state): return 5.5 + 0.2 * random.random()\n",
    "def predict_medium_score(state): return 5.0 + 0.5 * random.random()\n",
    "def predict_hard_score(state): return 4.5 + 0.8 * random.random()\n",
    "\n",
    "# -----------------------------\n",
    "# X√°c ƒë·ªãnh quiz m·ª•c ti√™u s·∫Øp t·ªõi (easy ‚Üí medium ‚Üí hard)\n",
    "# -----------------------------\n",
    "def determine_target_level(state):\n",
    "    scores = state[\"quiz_avg_scores\"]\n",
    "    if scores[\"easy\"] is None or scores[\"easy\"] < 6: return \"easy\"\n",
    "    if scores[\"medium\"] is None or scores[\"medium\"] < 6: return \"medium\"\n",
    "    return \"hard\"\n",
    "\n",
    "# -----------------------------\n",
    "# M√¥ ph·ªèng h√†nh ƒë·ªông ƒë·ªÉ c·∫≠p nh·∫≠t state\n",
    "# -----------------------------\n",
    "def simulate_action(state, action):\n",
    "    new_state = {\n",
    "        \"quiz_avg_scores\": dict(state[\"quiz_avg_scores\"]),\n",
    "        \"pdf_views\": dict(state[\"pdf_views\"]),\n",
    "        \"video_views\": dict(state[\"video_views\"]),\n",
    "        \"forum_post_count\": state[\"forum_post_count\"],\n",
    "        \"assignment_status\": state[\"assignment_status\"],\n",
    "        \"cluster\": state[\"cluster\"]\n",
    "    }\n",
    "\n",
    "    parts = action.split(\":\")\n",
    "    act_type = parts[0]\n",
    "    target = parts[1] if len(parts) > 1 else None\n",
    "\n",
    "    if act_type == \"xem_pdf\":\n",
    "        new_state[\"pdf_views\"][target] = new_state[\"pdf_views\"].get(target, 0) + 1\n",
    "    elif act_type == \"xem_video\":\n",
    "        new_state[\"video_views\"][target] = new_state[\"video_views\"].get(target, 0) + 1\n",
    "    elif act_type == \"tham_gia_thao_luan\":\n",
    "        new_state[\"forum_post_count\"] += 1\n",
    "    elif act_type == \"nop_assignment\":\n",
    "        new_state[\"assignment_status\"] = 1\n",
    "\n",
    "    return new_state\n",
    "\n",
    "# -----------------------------\n",
    "# Vector h√≥a state ƒë·ªÉ d√πng l√†m key trong Q-table\n",
    "# -----------------------------\n",
    "def vectorize_state(state):\n",
    "    return (\n",
    "        round(state[\"quiz_avg_scores\"][\"easy\"] if state[\"quiz_avg_scores\"][\"easy\"] is not None else -1, 1),\n",
    "        round(state[\"quiz_avg_scores\"][\"medium\"] if state[\"quiz_avg_scores\"][\"medium\"] is not None else -1, 1),\n",
    "        round(state[\"quiz_avg_scores\"][\"hard\"] if state[\"quiz_avg_scores\"][\"hard\"] is not None else -1, 1),\n",
    "        state[\"pdf_views\"].get(\"PDF_1_2_1\", 0),\n",
    "        state[\"pdf_views\"].get(\"PDF_1_2_2\", 0),\n",
    "        state[\"video_views\"].get(\"VID_1_2_1\", 0),\n",
    "        state[\"video_views\"].get(\"VID_1_2_2\", 0),\n",
    "        state[\"video_views\"].get(\"VID_1_2_3\", 0),\n",
    "        state[\"forum_post_count\"],\n",
    "        state[\"assignment_status\"],\n",
    "        state[\"cluster\"]\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# T√≠nh reward d·ª±a tr√™n ch√™nh l·ªách ƒëi·ªÉm d·ª± ƒëo√°n\n",
    "# -----------------------------\n",
    "def compute_reward(state, action):\n",
    "    target = determine_target_level(state)\n",
    "    current_score = state[\"quiz_avg_scores\"][target] or 0\n",
    "    next_state = simulate_action(state, action)\n",
    "\n",
    "    if target == \"easy\":\n",
    "        predicted_score = predict_easy_score(next_state)\n",
    "    elif target == \"medium\":\n",
    "        predicted_score = predict_medium_score(next_state)\n",
    "    else:\n",
    "        predicted_score = predict_hard_score(next_state)\n",
    "\n",
    "    return predicted_score - current_score\n",
    "\n",
    "# -----------------------------\n",
    "# Hu·∫•n luy·ªán Q-table\n",
    "# -----------------------------\n",
    "def train_q_table(episodes=5000, alpha=0.1, gamma=0.9, epsilon=1.0):\n",
    "    Q = defaultdict(float)\n",
    "    epsilon_decay = 0.995\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = random.choice(initial_state_pool)\n",
    "\n",
    "        for step in range(10):\n",
    "            state_key = vectorize_state(state)\n",
    "\n",
    "            # Ch·ªçn h√†nh ƒë·ªông theo epsilon-greedy\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(ACTIONS)\n",
    "            else:\n",
    "                action = max(ACTIONS, key=lambda a: Q[(state_key, a)])\n",
    "\n",
    "            # T√≠nh reward & c·∫≠p nh·∫≠t Q-value\n",
    "            reward = compute_reward(state, action)\n",
    "            next_state = simulate_action(state, action)\n",
    "            next_state_key = vectorize_state(next_state)\n",
    "            future_q = max([Q[(next_state_key, a)] for a in ACTIONS])\n",
    "\n",
    "            Q[(state_key, action)] += alpha * (reward + gamma * future_q - Q[(state_key, action)])\n",
    "\n",
    "            # C·∫≠p nh·∫≠t state\n",
    "            state = next_state\n",
    "\n",
    "        epsilon = max(0.05, epsilon * epsilon_decay)\n",
    "\n",
    "    print(f\"‚úÖ ƒê√£ train xong {episodes} l∆∞·ª£t, total Q-state-action: {len(Q)}\")\n",
    "    return Q\n",
    "\n",
    "# -----------------------------\n",
    "# G·ª£i √Ω h√†nh ƒë·ªông ti·∫øp theo t·ª´ Q-table\n",
    "# -----------------------------\n",
    "def suggest_next_action(state, Q):\n",
    "    state_key = vectorize_state(state)\n",
    "    print(f\"\\nüß† State key: {state_key}\")\n",
    "\n",
    "    scores = {a: Q.get((state_key, a), 0) for a in ACTIONS}\n",
    "    for a, q in scores.items():\n",
    "        print(f\"üîπ {a}: Q = {q:.4f}\")\n",
    "    best_action = max(scores, key=scores.get)\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c475bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def suggest_next_action(state, Q):\n",
    "    state_key = vectorize_state(state)\n",
    "    print(f\"\\nüß† State key: {state_key}\")\n",
    "    scores = {a: Q.get((state_key, a), 0) for a in ACTIONS}\n",
    "    for a, score in scores.items():\n",
    "        print(f\"üîπ {a}: Q = {score:.4f}\")\n",
    "    best_action = max(scores, key=scores.get)\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa0fd37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ train xong 1000 l∆∞·ª£t, total Q-state-action: 7500\n",
      "\n",
      "üß† State key: (7.2, 2, -1, 100, 0, 1, 0, 0, 1, 0, 2)\n",
      "üîπ xem_pdf:PDF_1_2_1: Q = 9.6472\n",
      "üîπ xem_pdf:PDF_1_2_2: Q = 15.7057\n",
      "üîπ xem_video:VID_1_2_1: Q = 16.9541\n",
      "üîπ xem_video:VID_1_2_2: Q = 13.2341\n",
      "üîπ xem_video:VID_1_2_3: Q = 6.6554\n",
      "üîπ lam_quiz:QUIZ_1_2_EASY: Q = 30.8700\n",
      "üîπ lam_quiz:QUIZ_1_2_MEDIUM: Q = 31.3039\n",
      "üîπ lam_quiz:QUIZ_1_2_HARD: Q = 32.5837\n",
      "üîπ tham_gia_thao_luan: Q = 17.8575\n",
      "üîπ nop_assignment: Q = 13.4267\n",
      "üëâ G·ª£i √Ω h·ªçc ti·∫øp theo: lam_quiz:QUIZ_1_2_HARD\n"
     ]
    }
   ],
   "source": [
    "Q = train_q_table(episodes=1000)\n",
    "\n",
    "\n",
    "current_state = {\n",
    "    \"quiz_avg_scores\": {\"easy\": 7.2, \"medium\": 2, \"hard\": None},\n",
    "    \"pdf_views\": {\"PDF_1_2_1\": 100, \"PDF_1_2_2\": 0},\n",
    "    \"video_views\": {\"VID_1_2_1\": 1, \"VID_1_2_2\": 0, \"VID_1_2_3\": 0},\n",
    "    \"forum_post_count\": 1,\n",
    "    \"assignment_status\": 0,\n",
    "    \"cluster\": 2\n",
    "}\n",
    "\n",
    "action = suggest_next_action(current_state, Q)\n",
    "print(\"üëâ G·ª£i √Ω h·ªçc ti·∫øp theo:\", action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
