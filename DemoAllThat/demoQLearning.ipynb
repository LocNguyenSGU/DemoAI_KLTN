{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45708b42",
   "metadata": {},
   "source": [
    "## demo Qlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99674179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Danh s√°ch h√†nh ƒë·ªông cho m·ª•c 1_2\n",
    "# -----------------------------\n",
    "ACTIONS = [\n",
    "    \"xem_pdf:PDF_1_2_1\",\n",
    "    \"xem_pdf:PDF_1_2_2\",\n",
    "    \"xem_video:VID_1_2_1\",\n",
    "    \"xem_video:VID_1_2_2\",\n",
    "    \"xem_video:VID_1_2_3\",\n",
    "    \"lam_quiz:QUIZ_1_2_EASY\",\n",
    "    \"lam_quiz:QUIZ_1_2_MEDIUM\",\n",
    "    \"lam_quiz:QUIZ_1_2_HARD\",\n",
    "    \"tham_gia_thao_luan:\",\n",
    "    \"nop_assignment:\"\n",
    "]\n",
    "\n",
    "initial_state_pool = [\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 6.0,\n",
    "        f\"quiz_avg_medium_1_2_1\": 4.2,\n",
    "        f\"quiz_avg_hard_1_2_1\": -1,\n",
    "        f\"pdf_views_1_2_1\": 2,\n",
    "        f\"video_views_1_2_1\": 3,\n",
    "        \"forum_post_count\": 1,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 0\n",
    "    },\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 7.5,\n",
    "        f\"quiz_avg_medium_1_2_1\": 6.0,\n",
    "        f\"quiz_avg_hard_1_2_1\": 3.2,\n",
    "        f\"pdf_views_1_2_1\": 5,\n",
    "        f\"video_views_1_2_1\": 8,\n",
    "        \"forum_post_count\": 2,\n",
    "        \"assignment_status\": 1,\n",
    "        \"cluster\": 0\n",
    "    },\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 3.0,\n",
    "        f\"quiz_avg_medium_1_2_1\": 2.5,\n",
    "        f\"quiz_avg_hard_1_2_1\": -1,\n",
    "        f\"pdf_views_1_2_1\": 1,\n",
    "        f\"video_views_1_2_1\": 1,\n",
    "        \"forum_post_count\": 0,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 1\n",
    "    },\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 5.5,\n",
    "        f\"quiz_avg_medium_1_2_1\": 5.0,\n",
    "        f\"quiz_avg_hard_1_2_1\": -1,\n",
    "        f\"pdf_views_1_2_1\": 3,\n",
    "        f\"video_views_1_2_1\": 2,\n",
    "        \"forum_post_count\": 1,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 1\n",
    "    }\n",
    "]\n",
    "# -----------------------------\n",
    "# D·ª± ƒëo√°n ƒëi·ªÉm v·ªõi model th·∫≠t\n",
    "# -----------------------------\n",
    "def predict_score(state, level, section, models_dict):\n",
    "    X = []\n",
    "\n",
    "    X.append(state[f\"video_views_{section}_1\"])\n",
    "    X.append(state[f\"pdf_views_{section}_1\"])\n",
    "\n",
    "    if level == \"medium\":\n",
    "        X.append(state[f\"quiz_avg_easy_{section}_1\"])\n",
    "    elif level == \"hard\":\n",
    "        X.append(state[f\"quiz_avg_easy_{section}_1\"])\n",
    "        X.append(state[f\"quiz_avg_medium_{section}_1\"])\n",
    "\n",
    "    X.append(state[\"forum_post_count\"])\n",
    "    X.append(state[\"assignment_status\"])\n",
    "    X.append(state[\"cluster\"])\n",
    "   \n",
    "    model_key = f\"{level}_{section}\"\n",
    "    model = models_dict[model_key]\n",
    "\n",
    "    X_df = pd.DataFrame([X], columns=model.feature_names_in_)\n",
    "    return model.predict(X_df)[0]\n",
    "\n",
    "# -----------------------------\n",
    "# X√°c ƒë·ªãnh level m·ª•c ti√™u ti·∫øp theo\n",
    "# -----------------------------\n",
    "def determine_target_level(state, section):\n",
    "    easy = state.get(f\"quiz_avg_easy_{section}_1\", None)\n",
    "    medium = state.get(f\"quiz_avg_medium_{section}_1\", None)\n",
    "    hard = state.get(f\"quiz_avg_hard_{section}_1\", None)\n",
    "\n",
    "    if easy is None or easy < 6: return \"easy\"\n",
    "    if medium is None or medium < 6: return \"medium\"\n",
    "    return \"hard\"\n",
    "\n",
    "# -----------------------------\n",
    "# Gi·∫£ l·∫≠p action ‚Üí sinh ra state m·ªõi\n",
    "# -----------------------------\n",
    "def simulate_action(state, action, section):\n",
    "    # state = dict(state)  # clone\n",
    "    state = dict(random.choice(initial_state_pool)) \n",
    "    \n",
    "    parts = action.split(\":\")\n",
    "    act_type = parts[0]\n",
    "    target = parts[1] if len(parts) > 1 else None\n",
    "\n",
    "    if act_type == \"xem_pdf\":\n",
    "        state[f\"pdf_views_{section}_1\"] += 1\n",
    "    elif act_type == \"xem_video\":\n",
    "        state[f\"video_views_{section}_1\"] += 1\n",
    "    elif act_type == \"tham_gia_thao_luan\":\n",
    "        state[\"forum_post_count\"] += 1\n",
    "    elif act_type == \"nop_assignment\":\n",
    "        state[\"assignment_status\"] = 1\n",
    "\n",
    "    return state\n",
    "\n",
    "# -----------------------------\n",
    "# T√≠nh reward b·∫±ng Linear Regression th·∫≠t\n",
    "# -----------------------------\n",
    "def compute_reward(state, action, section, models_c0, models_c1):\n",
    "    cluster = state[\"cluster\"]\n",
    "    models = models_c0 if cluster == 0 else models_c1\n",
    "\n",
    "    target_level = determine_target_level(state, section)\n",
    "    current_score = state.get(f\"quiz_avg_{target_level}_{section}_1\", 0)\n",
    "\n",
    "    next_state = simulate_action(state, action, section)\n",
    "    predicted_score = predict_score(next_state, target_level, section, models)\n",
    "\n",
    "    return predicted_score - current_score\n",
    "\n",
    "# -----------------------------\n",
    "# Vector h√≥a state\n",
    "# -----------------------------\n",
    "def vectorize_state(state, section):\n",
    "    return (\n",
    "        round(state[f\"quiz_avg_easy_{section}_1\"], 1),\n",
    "        round(state[f\"quiz_avg_medium_{section}_1\"], 1),\n",
    "        round(state[f\"quiz_avg_hard_{section}_1\"], 1),\n",
    "        state[f\"pdf_views_{section}_1\"],\n",
    "        state[f\"video_views_{section}_1\"],\n",
    "        state[\"forum_post_count\"],\n",
    "        state[\"assignment_status\"],\n",
    "        state[\"cluster\"]\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# Q-learning\n",
    "# -----------------------------\n",
    "def train_q_table(section, models_c0, models_c1, episodes=1000):\n",
    "    Q = defaultdict(float)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = {\n",
    "            f\"quiz_avg_easy_{section}_1\": round(random.uniform(3, 7), 1),\n",
    "            f\"quiz_avg_medium_{section}_1\": round(random.uniform(1, 6), 1),\n",
    "            f\"quiz_avg_hard_{section}_1\": -1.0,\n",
    "            f\"pdf_views_{section}_1\": random.randint(0, 5),\n",
    "            f\"video_views_{section}_1\": random.randint(0, 5),\n",
    "            \"forum_post_count\": random.randint(0, 3),\n",
    "            \"assignment_status\": random.randint(0, 1),\n",
    "            \"cluster\": random.randint(0, 1)\n",
    "        }\n",
    "\n",
    "        for step in range(10):\n",
    "            s_key = vectorize_state(state, section)\n",
    "\n",
    "            # Ch·ªçn h√†nh ƒë·ªông\n",
    "            action = random.choice(ACTIONS)\n",
    "\n",
    "            # Reward\n",
    "            reward = compute_reward(state, action, section, models_c0, models_c1)\n",
    "\n",
    "            # Q-learning update\n",
    "            next_state = simulate_action(state, action, section)\n",
    "            next_s_key = vectorize_state(next_state, section)\n",
    "            future_q = max([Q[(next_s_key, a)] for a in ACTIONS])\n",
    "            Q[(s_key, action)] += 0.1 * (reward + 0.9 * future_q - Q[(s_key, action)])\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    print(f\"‚úÖ ƒê√£ train xong {episodes} l∆∞·ª£t Q-learning v·ªõi m·ª•c {section}\")\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba7416",
   "metadata": {},
   "source": [
    "### C√°ch d√πng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff1f5bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ train xong 1000 l∆∞·ª£t Q-learning v·ªõi m·ª•c 1_2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "section = \"1_2\"\n",
    "\n",
    "models_c0 = joblib.load(\"models/models_cluster_0.pkl\")\n",
    "models_c1 = joblib.load(\"models/models_cluster_1.pkl\")\n",
    "Q = train_q_table(section, models_c0, models_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e1efa",
   "metadata": {},
   "source": [
    "###  G·ª£i √Ω h√†nh ƒë·ªông cho h·ªçc vi√™n c·ª• th·ªÉ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8da9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_next_action(state, Q, section):\n",
    "    s_key = vectorize_state(state, section)\n",
    "    actions_q = {a: Q.get((s_key, a), 0) for a in ACTIONS}\n",
    "\n",
    "    print(\"üß† Q-values:\")\n",
    "    for a, q in actions_q.items():\n",
    "        print(f\"  {a:25} ‚Üí Q = {q:.3f}\")\n",
    "\n",
    "    best = max(actions_q, key=actions_q.get)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba60898",
   "metadata": {},
   "source": [
    "### V√≠ d·ª• test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53ca1723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üßë‚Äçüéì H·ªçc vi√™n 1 ===\n",
      "üß† Q-values:\n",
      "  xem_pdf:PDF_1_2_1         ‚Üí Q = 6.754\n",
      "  xem_pdf:PDF_1_2_2         ‚Üí Q = 6.855\n",
      "  xem_video:VID_1_2_1       ‚Üí Q = 6.720\n",
      "  xem_video:VID_1_2_2       ‚Üí Q = 8.682\n",
      "  xem_video:VID_1_2_3       ‚Üí Q = 8.324\n",
      "  lam_quiz:QUIZ_1_2_EASY    ‚Üí Q = 6.883\n",
      "  lam_quiz:QUIZ_1_2_MEDIUM  ‚Üí Q = 6.789\n",
      "  lam_quiz:QUIZ_1_2_HARD    ‚Üí Q = 7.413\n",
      "  tham_gia_thao_luan:       ‚Üí Q = 4.725\n",
      "  nop_assignment:           ‚Üí Q = 5.767\n",
      "üëâ G·ª£i √Ω h·ªçc ti·∫øp theo: xem_video:VID_1_2_2\n",
      "\n",
      "=== üßë‚Äçüéì H·ªçc vi√™n 2 ===\n",
      "üß† Q-values:\n",
      "  xem_pdf:PDF_1_2_1         ‚Üí Q = 0.000\n",
      "  xem_pdf:PDF_1_2_2         ‚Üí Q = 0.000\n",
      "  xem_video:VID_1_2_1       ‚Üí Q = 0.000\n",
      "  xem_video:VID_1_2_2       ‚Üí Q = 0.000\n",
      "  xem_video:VID_1_2_3       ‚Üí Q = 0.000\n",
      "  lam_quiz:QUIZ_1_2_EASY    ‚Üí Q = 0.000\n",
      "  lam_quiz:QUIZ_1_2_MEDIUM  ‚Üí Q = 0.000\n",
      "  lam_quiz:QUIZ_1_2_HARD    ‚Üí Q = 0.000\n",
      "  tham_gia_thao_luan:       ‚Üí Q = 0.000\n",
      "  nop_assignment:           ‚Üí Q = 0.000\n",
      "üëâ G·ª£i √Ω h·ªçc ti·∫øp theo: xem_pdf:PDF_1_2_1\n",
      "\n",
      "=== üßë‚Äçüéì H·ªçc vi√™n 3 ===\n",
      "üß† Q-values:\n",
      "  xem_pdf:PDF_1_2_1         ‚Üí Q = 9.464\n",
      "  xem_pdf:PDF_1_2_2         ‚Üí Q = 7.943\n",
      "  xem_video:VID_1_2_1       ‚Üí Q = 8.189\n",
      "  xem_video:VID_1_2_2       ‚Üí Q = 8.215\n",
      "  xem_video:VID_1_2_3       ‚Üí Q = 8.389\n",
      "  lam_quiz:QUIZ_1_2_EASY    ‚Üí Q = 9.299\n",
      "  lam_quiz:QUIZ_1_2_MEDIUM  ‚Üí Q = 10.625\n",
      "  lam_quiz:QUIZ_1_2_HARD    ‚Üí Q = 8.601\n",
      "  tham_gia_thao_luan:       ‚Üí Q = 7.591\n",
      "  nop_assignment:           ‚Üí Q = 7.193\n",
      "üëâ G·ª£i √Ω h·ªçc ti·∫øp theo: lam_quiz:QUIZ_1_2_MEDIUM\n"
     ]
    }
   ],
   "source": [
    "test_states = [\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 6.0,\n",
    "        f\"quiz_avg_medium_1_2_1\": 4.2,\n",
    "        f\"quiz_avg_hard_1_2_1\": -1,\n",
    "        f\"pdf_views_1_2_1\": 2,\n",
    "        f\"video_views_1_2_1\": 3,\n",
    "        \"forum_post_count\": 1,\n",
    "        \"assignment_status\": 0,\n",
    "        \"cluster\": 0\n",
    "    },\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 7.5,\n",
    "        f\"quiz_avg_medium_1_2_1\": 6.0,\n",
    "        f\"quiz_avg_hard_1_2_1\": 3.2,\n",
    "        f\"pdf_views_1_2_1\": 5,\n",
    "        f\"video_views_1_2_1\": 4,\n",
    "        \"forum_post_count\": 2,\n",
    "        \"assignment_status\": 1,\n",
    "        \"cluster\": 0\n",
    "    },\n",
    "    {\n",
    "        f\"quiz_avg_easy_1_2_1\": 7.5,\n",
    "        f\"quiz_avg_medium_1_2_1\": 6.0,\n",
    "        f\"quiz_avg_hard_1_2_1\": 3.2,\n",
    "        f\"pdf_views_1_2_1\": 5,\n",
    "        f\"video_views_1_2_1\": 8,\n",
    "        \"forum_post_count\": 2,\n",
    "        \"assignment_status\": 1,\n",
    "        \"cluster\": 0\n",
    "    }\n",
    "]\n",
    "for i, test_state in enumerate(test_states, start=1):\n",
    "    print(f\"\\n=== üßë‚Äçüéì H·ªçc vi√™n {i} ===\")\n",
    "    action = suggest_next_action(test_state, Q, section=\"1_2\")\n",
    "    print(f\"üëâ G·ª£i √Ω h·ªçc ti·∫øp theo: {action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
